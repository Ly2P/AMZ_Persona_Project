{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "from fake_useragent import UserAgent\n",
    "import concurrent.futures\n",
    "from tqdm import notebook\n",
    "from itertools import repeat\n",
    "import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_data = pd.read_csv('user_review_v1_MOBIUZ.csv',encoding='utf-8')\n",
    "print(len(crawl_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = UserAgent()\n",
    "ua = user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_list=['45.63.19.165:80','34.134.60.185:443','184.177.84.245:1088','50.250.205.21:32100','67.201.33.10:25283','71.71.162.234:39593','185.59.66.210:33611','181.209.219.28:4153','64.124.191.98:32688',\n",
    "'12.216.103.114:39072','38.133.200.94:31596','174.108.154.129:32940','70.60.230.8:34116','170.106.155.14:1080','181.129.144.59:3629']\n",
    "test_proxy = {f'{proxy}':0 for proxy in proxy_list}\n",
    "print(test_proxy)\n",
    "def proxy(idx):\n",
    "    proxies = {\"http\":\"socks4://\"+str(proxy_list[idx%len(proxy_list)])}\n",
    "    return proxies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cookies(asin):\n",
    "    url = str('https://www.amazon.com/dp/'+str(asin)+'?th=1')\n",
    "    headers={'User-agent':ua.random}\n",
    "    res = requests.get(url,headers = headers)\n",
    "    cookiejar = res.cookies\n",
    "    return cookiejar\n",
    "\n",
    "#get_cookies(crawl_data['Asin'][randint(0,50)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_asin=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_web(url,idx):\n",
    "    headers={'User-agent':ua.random,\n",
    "        'Cookie':str(get_cookies(crawl_data['Asin'][randint(0,50)]))}\n",
    "    prox = proxy(idx)\n",
    "    try:\n",
    "        response = requests.get(url,headers=headers,proxies=prox)\n",
    "        txt = response.text\n",
    "        return txt\n",
    "    except:\n",
    "        #test_proxy[str(f'{prox}')] += 1\n",
    "        failed_asin.append(url)\n",
    "        print('Requests Failed')\n",
    "        return False\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(soap):\n",
    "    category = soap.find_all(\"a\",class_=\"a-link-normal a-color-tertiary\")\n",
    "    price = soap.find(\"span\",class_='a-offscreen')\n",
    "    try:\n",
    "        brand = soap.find(text='Brand').findNext('td').text\n",
    "    except:\n",
    "        brand = 'None'\n",
    "    if category != []:\n",
    "        category = [str(t).split('\">')[1].split('</a>')[0].replace(\" \",\"\").replace('\\n',\"\").replace('&amp;',\"\") for t in category]\n",
    "        try:\n",
    "            price = str(price).split('$')[1].replace('</span>','')\n",
    "        except:\n",
    "            price = 'Non-Available'\n",
    "        content_dict={'category':category,'price':price,'Brand':brand}\n",
    "        return content_dict\n",
    "    else:\n",
    "        #print('Content Failed')\n",
    "        return False\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape(arg):\n",
    "    url,idx = arg\n",
    "    tmp_format = pd.DataFrame({'Asin':[],'Brand':[],'Category':[],'Sub_category':[],'Breakdown_category':[],'Price':[]})\n",
    "    if request_web(url,idx) != False:\n",
    "        soap = BeautifulSoup(request_web(url,idx),\"lxml\")\n",
    "        if get_content(soap) != False:\n",
    "            brand = get_content(soap)['Brand']\n",
    "            category = get_content(soap)['category']\n",
    "            price = get_content(soap)['price']\n",
    "            tmp_format = tmp_format.append({\n",
    "            'Asin':url.split('/dp/')[1],'Category':[category[1]],'Sub_category':[category[-2]],\n",
    "            'Breakdown_category':category[-1],'Price':[price],'Brand':[brand]},ignore_index=True)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            failed_asin.append(url)\n",
    "            time.sleep(2)\n",
    "                \n",
    "    return tmp_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_asin=[]\n",
    "final_format=pd.DataFrame({'Asin':[],'Brand':[],'Category':[],'Sub_category':[],'Breakdown_category':[],'Price':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    base_url = 'https://www.amazon.com'\n",
    "    url_list=[f\"{base_url}/dp/{asin}\" for asin in crawl_data['Asin']]\n",
    "    tmp_format = pd.DataFrame({'Asin':[],'Brand':[],'Category':[],'Sub_category':[],'Breakdown_category':[],'Price':[]})\n",
    "    idx_list=[]\n",
    "    for idx in range(len(crawl_data)-1):\n",
    "        idx_list.append(idx)\n",
    "    arg = list(zip(url_list,idx_list))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:\n",
    "        for result in tqdm.tqdm_notebook((executor.map(scrape,arg)),total=len(url_list)):\n",
    "           tmp_format = tmp_format.append(result,ignore_index = True)\n",
    "        executor.shutdown()\n",
    "    return tmp_format\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_format = run()\n",
    "print('__________________RESULT_____________________')\n",
    "print('失敗數:'+str(len(failed_asin)),\n",
    "      'Proxy error:'+str(test_proxy),\n",
    "      final_format,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_format.to_csv('Asin_Category_MOBIUZ_list1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retry failed URLs in first crawling \n",
    "##### Retry Loop until it done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(failed_asin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_format = pd.DataFrame({'fail':failed_asin})\n",
    "failed_format.to_csv('failed_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed2_asin=pd.read_csv('failed_list.csv')['fail']\n",
    "failed2_asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_asin=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail_run():\n",
    "    url_list=[asin for asin in failed2_asin]\n",
    "    tmp_format = pd.DataFrame({'Asin':[],'Category':[],'Sub_category':[],'Breakdown_category':[],'Price':[]})\n",
    "    idx_list=[]\n",
    "    for idx in range(len(failed2_asin)-1):\n",
    "        idx_list.append(idx)\n",
    "    arg = list(zip(url_list,idx_list))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for result in tqdm.tqdm_notebook((executor.map(scrape,arg)),total=len(url_list)):\n",
    "           tmp_format = tmp_format.append(result,ignore_index = True)\n",
    "        executor.shutdown()\n",
    "    return tmp_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_format = fail_run()\n",
    "print('__________________RESULT_____________________')\n",
    "print('失敗數:'+str(len(failed_asin)),\n",
    "      'Proxy error:'+str(test_proxy),\n",
    "      retry_format,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_format.to_csv('Asin_Category_retry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat 1st & 2nd Crawling result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = pd.read_csv('Asin_Category_MOBIUZ_list1.csv')\n",
    "retry= pd.read_csv('Asin_Category_retry.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all = pd.concat([one,retry],ignore_index = True)\n",
    "print(concat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all.to_csv('Asin_Category_MOBIUZ_list.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a22652e4c5420ca48c466d028533d7d344d7156c9445b0b6e045b564dc456b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
